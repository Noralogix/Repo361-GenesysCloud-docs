{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65cc671f-1102-4b40-baa4-0f255fffde53",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rawdata_client_id = ''\n",
    "rawdata_client_secret = ''\n",
    "rawdata_date = '20240905'  # Example date in YYYYMMDD format\n",
    "rawdata_format = 'avro'        # Example format (could be 'csv', 'avro'.)\n",
    "\n",
    "# Directory to save Avro files (if using Databricks, this should be in the /dbfs/ directory)\n",
    "avro_dir = '/dbfs/tmp/avro_files/'\n",
    "\n",
    "rawdata_token_url = 'https://api.repo361.com/security/oauth2/token'\n",
    "rawdata_api_url = 'https://api.repo361.com/rawdata/export'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7438036f-643f-46cc-80a9-9468d8a5af36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db9eac20-157f-4854-83e8-8744fd26a698",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(avro_dir):\n",
    "    os.makedirs(avro_dir)\n",
    "else:\n",
    "    shutil.rmtree(avro_dir)\n",
    "    os.makedirs(avro_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0be988e9-4b3b-4fd9-b7c9-ac31395a35a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#OAuth 2.0 access token\n",
    "access_token = ''\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/x-www-form-urlencoded'\n",
    "}\n",
    "# Define the form data for the token request\n",
    "data = {\n",
    "    'client_id': rawdata_client_id,\n",
    "    'client_secret': rawdata_client_secret,\n",
    "    'grant_type': 'client_credentials'\n",
    "}\n",
    "\n",
    "# Send POST request to get the access token\n",
    "response = requests.post(rawdata_token_url, headers=headers, data=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response and return the access token\n",
    "    token_data = response.json()\n",
    "    access_token = token_data['access_token']\n",
    "else:\n",
    "    print(f\"Failed to get access token. Status Code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b77f379-f835-4037-854f-1e6653a14378",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "headers = {'Authorization': 'Bearer ' + access_token}\n",
    "\n",
    "# Define the body of the POST request with parameters 'date' and 'format'\n",
    "payload = {\n",
    "    'Date': rawdata_date,\n",
    "    'Format': rawdata_format\n",
    "}\n",
    "\n",
    "# Send the POST request with the body payload and headers\n",
    "response = requests.post(rawdata_api_url, headers=headers, json=payload)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    response_data = response.json()\n",
    "\n",
    "    # Extract 'files' object from the response\n",
    "    files = response_data.get('files', [])\n",
    "    print(f\"Number of avro files: {len(files)}\")\n",
    "\n",
    "    # Download each file\n",
    "    for file in files:\n",
    "        file_name = file.get('name')\n",
    "        file_url = file.get('url')\n",
    "\n",
    "        # Ensure the file name has .avro extension\n",
    "        if not file_name.endswith('.avro'):\n",
    "            file_name += '.avro'\n",
    "\n",
    "        # Full path where the Avro file will be saved\n",
    "        file_path = os.path.join(avro_dir, file_name)\n",
    "\n",
    "        # Download the file from the URL\n",
    "        file_response = requests.get(file_url)\n",
    "        if file_response.status_code == 200:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(file_response.content)\n",
    "        else:\n",
    "            print(f\"Failed to download {file_name}. Status Code: {file_response.status_code}\")    \n",
    "else:\n",
    "    print(f\"Failed to fetch URLs from API. Status Code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37650ebc-6bd4-4e4a-9ffc-fa7c5a18d6c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install fastavro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae1c31c9-5f39-4787-b730-a1e4a94f75aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb6dc42b-ea79-4641-8c84-7c142ee17418",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store records\n",
    "records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57ec0d7e-7be0-4ea1-83c6-477575784568",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import fastavro\n",
    "\n",
    "# Path to the Avro file in DBFS\n",
    "avro_file_path = \"/dbfs/tmp/avro_files/conversations_detail_without_attributes_001.avro\"\n",
    "\n",
    "# Open the Avro file and extract its schema\n",
    "with open(avro_file_path, 'rb') as file:\n",
    "    reader = fastavro.reader(file)\n",
    "    # Avro Schema\n",
    "    #schema = reader.schema    \n",
    "    # Iterate over each record in the Avro file\n",
    "    for record in reader:                        \n",
    "        for conv in record['Entities']:\n",
    "            conversation_data = {\n",
    "                \"ConversationId\": conv['ConversationId'],\n",
    "                \"ConversationStart\": conv['ConversationStart'],\n",
    "                \"ConversationEnd\": conv['ConversationEnd'],\n",
    "                \"Participants\": []\n",
    "            }            \n",
    "            # Extract participants and sessions details\n",
    "            for part in conv['Participants']:\n",
    "                participant_data = {\n",
    "                    \"ParticipantId\": part['ParticipantId'],\n",
    "                    \"ParticipantName\": part['ParticipantName'],\n",
    "                    \"Purpose\": part['Purpose'],\n",
    "                    \"UserId\": part['UserId'],\n",
    "                    \"Sessions\": []\n",
    "                }                \n",
    "                # Extract session details and metrics\n",
    "                for ss in part['Sessions']:\n",
    "                    session_data = {\n",
    "                        \"MediaType\": ss['MediaType'],\n",
    "                        \"Direction\": ss['Direction'],\n",
    "                        \"SessionId\": ss['SessionId'],\n",
    "                        \"OutboundContactListId\": ss['OutboundContactListId'],\n",
    "                        \"OutboundContactId\": ss['OutboundContactId'],\n",
    "                        \"OutboundCampaignId\": ss['OutboundCampaignId'],\n",
    "                        \"Ani\": ss['Ani'],\n",
    "                        \"Dnis\": ss['Dnis'],\n",
    "                        \"Segments\": [],\n",
    "                        \"Metrics\": []\n",
    "                    }                    \n",
    "                    # Extract metrics\n",
    "                    for mm in ss['Metrics']:\n",
    "                        metric_data = {\n",
    "                            \"Name\": mm['Name'],\n",
    "                            \"Value\": mm['Value'],\n",
    "                            \"EmitDate\": mm['EmitDate']\n",
    "                        }\n",
    "                        session_data[\"Metrics\"].append(metric_data)                    \n",
    "                    # Extract segments\n",
    "                    for sgm in ss['Segments']:\n",
    "                        sgm_data = {\n",
    "                            \"DisconnectType\": sgm['DisconnectType'],\n",
    "                            \"SegmentType\": sgm['SegmentType'],\n",
    "                            \"SegmentStart\": sgm['SegmentStart'],\n",
    "                            \"SegmentEnd\": sgm['SegmentEnd'],\n",
    "                            \"QueueId\": sgm['QueueId'],\n",
    "                            \"WrapUpCode\": sgm['WrapUpCode']\n",
    "                        }\n",
    "                        session_data[\"Segments\"].append(sgm_data)                                            \n",
    "                    participant_data[\"Sessions\"].append(session_data)                \n",
    "                conversation_data[\"Participants\"].append(participant_data)            \n",
    "            # Append the conversation data to the list of records\n",
    "            records.append(conversation_data)\n",
    "\n",
    "print(f\"Number of records: {len(records)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acd0646d-ffa7-45e1-a7fe-84b1055aabef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, LongType, TimestampType\n",
    "\n",
    "# Define the schema for Metrics\n",
    "metrics_schema = StructType([\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Value\", LongType(), True),\n",
    "    StructField(\"EmitDate\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "# Define the schema for Segments\n",
    "segments_schema = StructType([\n",
    "    StructField(\"DisconnectType\", StringType(), True),\n",
    "    StructField(\"SegmentType\", StringType(), True),\n",
    "    StructField(\"SegmentStart\", TimestampType(), True),\n",
    "    StructField(\"SegmentEnd\", TimestampType(), True),\n",
    "    StructField(\"QueueId\", StringType(), True),\n",
    "    StructField(\"WrapUpCode\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Define the schema for Sessions\n",
    "sessions_schema = StructType([\n",
    "    StructField(\"MediaType\", StringType(), True),\n",
    "    StructField(\"Direction\", StringType(), True),\n",
    "    StructField(\"SessionId\", StringType(), True),\n",
    "    StructField(\"OutboundContactListId\", StringType(), True),\n",
    "    StructField(\"OutboundContactId\", StringType(), True),\n",
    "    StructField(\"OutboundCampaignId\", StringType(), True),\n",
    "    StructField(\"Ani\", StringType(), True),\n",
    "    StructField(\"Dnis\", StringType(), True),\n",
    "    StructField(\"Segments\", ArrayType(segments_schema), True),\n",
    "    StructField(\"Metrics\", ArrayType(metrics_schema), True)\n",
    "])\n",
    "\n",
    "# Define the schema for Participants\n",
    "participants_schema = StructType([\n",
    "    StructField(\"ParticipantId\", StringType(), True),\n",
    "    StructField(\"ParticipantName\", StringType(), True),\n",
    "    StructField(\"Purpose\", StringType(), True),\n",
    "    StructField(\"UserId\", StringType(), True),\n",
    "    StructField(\"Sessions\", ArrayType(sessions_schema), True)\n",
    "])\n",
    "\n",
    "# Define the final schema for Conversation\n",
    "conversation_schema = StructType([\n",
    "    StructField(\"ConversationId\", StringType(), True),\n",
    "    StructField(\"ConversationStart\", TimestampType(), True),\n",
    "    StructField(\"ConversationEnd\", TimestampType(), True),\n",
    "    StructField(\"Participants\", ArrayType(participants_schema), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1648cfb-566a-4018-8a24-78262faef059",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row  # Import Row from pyspark.sql\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder.appName(\"AvroToDataFrame\").getOrCreate()\n",
    "\n",
    "# Convert each record (a dictionary) into a Row object\n",
    "rows = [Row(**record) for record in records]\n",
    "\n",
    "# Create a DataFrame using the explicitly defined schema\n",
    "df = spark.createDataFrame(rows, schema=conversation_schema)\n",
    "\n",
    "# Show the DataFrame\n",
    "#df.show(truncate=False)\n",
    "\n",
    "# Print the schema of the DataFrame\n",
    "#df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1190dbc-a27c-492c-9637-a31faf93835c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Explode Participants array\n",
    "df_participants = df.withColumn(\"participant\", F.explode(\"Participants\"))\n",
    "\n",
    "# Explode Sessions array within each Participant\n",
    "df_sessions = df_participants.withColumn(\"session\", F.explode(\"participant.Sessions\"))\n",
    "\n",
    "# Explode Metrics array within each Session\n",
    "df_metrics = df_sessions.withColumn(\"metric\", F.explode(\"session.Metrics\"))\n",
    "\n",
    "# Select the required fields\n",
    "df_selected_metrics = df_metrics.select(\n",
    "    \"ConversationId\",\n",
    "    \"ConversationStart\",\n",
    "    \"ConversationEnd\",\n",
    "    \"participant.ParticipantName\",\n",
    "    \"metric.Name\",\n",
    "    \"metric.Value\",\n",
    "    \"metric.EmitDate\"\n",
    ")\n",
    "\n",
    "# Add the filter to only select rows where the metric is not null\n",
    "df_filtered_metrics = df_selected_metrics.filter(\n",
    "    (F.col(\"metric.Name\").isNotNull()) & (F.col(\"metric.Value\").isNotNull())\n",
    ")\n",
    "\n",
    "# Show the filtered metrics\n",
    "df_filtered_metrics.show(truncate=False)\n",
    "\n",
    "# Print the schema of the filtered DataFrame\n",
    "#df_filtered_metrics.printSchema()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Repo361 RawData Avro",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
